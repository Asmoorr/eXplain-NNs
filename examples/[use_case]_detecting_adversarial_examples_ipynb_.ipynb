{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download of all dependencies for library (restart may be required)"
      ],
      "metadata": {
        "id": "gx2uR1Jx5EBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output"
      ],
      "metadata": {
        "id": "BiB2NXgxxU2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuFq_dWXiKNl",
        "outputId": "b84b807e-2cb7-4610-866a-ffa05fd78755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-08 10:19:22--  https://raw.githubusercontent.com/aimclub/eXplain-NNs/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1486 (1.5K) [text/plain]\n",
            "Saving to: ‘requirements.txt.2’\n",
            "\n",
            "requirements.txt.2  100%[===================>]   1.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-08 10:19:22 (16.4 MB/s) - ‘requirements.txt.2’ saved [1486/1486]\n",
            "\n",
            "Requirement already satisfied: asttokens==2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: attrs==22.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (22.1.0)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: comm==0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: contourpy==1.0.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.0.6)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: debugpy==1.6.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.6.4)\n",
            "Requirement already satisfied: decorator==5.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.1.1)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: executing==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: fonttools==4.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.38.0)\n",
            "Requirement already satisfied: giotto-ph==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.2.2)\n",
            "Requirement already satisfied: giotto-tda==0.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.6.0)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (3.4)\n",
            "Requirement already satisfied: igraph==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata==5.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (5.1.0)\n",
            "Requirement already satisfied: iniconfig==1.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.1.1)\n",
            "Requirement already satisfied: ipykernel==6.19.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (6.19.2)\n",
            "Requirement already satisfied: ipython==8.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (8.7.0)\n",
            "Requirement already satisfied: ipywidgets==8.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (8.0.3)\n",
            "Requirement already satisfied: jedi==0.18.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (0.18.2)\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (1.2.0)\n",
            "Requirement already satisfied: jupyter_client==7.4.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (7.4.8)\n",
            "Requirement already satisfied: jupyter_core==5.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (5.1.0)\n",
            "Requirement already satisfied: jupyterlab-widgets==3.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (1.4.4)\n",
            "Requirement already satisfied: llvmlite==0.39.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (0.39.1)\n",
            "Requirement already satisfied: matplotlib==3.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (3.6.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio==1.5.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.5.6)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.56.4)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (1.23.5)\n",
            "Requirement already satisfied: packaging==22.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (22.0)\n",
            "Requirement already satisfied: pandas==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (1.4.1)\n",
            "Requirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (0.8.3)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (0.7.5)\n",
            "Requirement already satisfied: Pillow==9.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (9.3.0)\n",
            "Requirement already satisfied: platformdirs==2.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (2.6.0)\n",
            "Requirement already satisfied: plotly==4.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (4.8.2)\n",
            "Requirement already satisfied: pluggy==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (1.0.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.36 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (3.0.36)\n",
            "Requirement already satisfied: psutil==5.9.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (5.9.4)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (0.7.0)\n",
            "Requirement already satisfied: pure-eval==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (0.2.2)\n",
            "Requirement already satisfied: py==1.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (1.11.0)\n",
            "Requirement already satisfied: pyflagser==0.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 49)) (0.4.5)\n",
            "Requirement already satisfied: Pygments==2.13.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (2.13.0)\n",
            "Requirement already satisfied: pynndescent==0.5.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 51)) (0.5.8)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 52)) (3.0.9)\n",
            "Requirement already satisfied: pytest==7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 53)) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 55)) (2022.6)\n",
            "Requirement already satisfied: pyzmq==24.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (24.0.1)\n",
            "Requirement already satisfied: requests==2.28.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (2.28.1)\n",
            "Requirement already satisfied: retrying==1.3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 59)) (1.2.0)\n",
            "Requirement already satisfied: scipy==1.9.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (1.9.3)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 61)) (1.16.0)\n",
            "Requirement already satisfied: stack-data==0.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 62)) (0.6.2)\n",
            "Requirement already satisfied: texttable==1.6.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 63)) (1.6.7)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 64)) (3.1.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 65)) (1.11.0)\n",
            "Requirement already satisfied: torchvision==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 66)) (0.12.0)\n",
            "Requirement already satisfied: tornado==6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 67)) (6.2)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (4.64.1)\n",
            "Requirement already satisfied: traitlets==5.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 69)) (5.7.1)\n",
            "Requirement already satisfied: typing_extensions==4.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 70)) (4.4.0)\n",
            "Requirement already satisfied: umap-learn==0.5.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (0.5.3)\n",
            "Requirement already satisfied: urllib3==1.26.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 72)) (1.26.13)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 73)) (0.2.5)\n",
            "Requirement already satisfied: widgetsnbextension==4.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 74)) (4.0.4)\n",
            "Requirement already satisfied: zipp==3.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 75)) (3.11.0)\n",
            "Requirement already satisfied: flake8==6.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 77)) (6.0.0)\n",
            "Requirement already satisfied: brunette==0.2.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 78)) (0.2.8)\n",
            "Requirement already satisfied: isort==5.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 79)) (5.12.0)\n",
            "Requirement already satisfied: add-trailing-comma==2.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 80)) (2.4.0)\n",
            "Requirement already satisfied: pep8-naming==0.13.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 82)) (0.13.3)\n",
            "Requirement already satisfied: flake8-bugbear==23.3.23 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 83)) (23.3.23)\n",
            "Requirement already satisfied: flake8-builtins==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 84)) (2.1.0)\n",
            "Requirement already satisfied: flake8-commas==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 85)) (2.1.0)\n",
            "Requirement already satisfied: flake8-variables-names==0.0.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 86)) (0.0.5)\n",
            "Requirement already satisfied: flake8-isort==6.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 87)) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->-r requirements.txt (line 33)) (67.7.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.2->-r requirements.txt (line 53)) (1.2.3)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from flake8==6.0.0->-r requirements.txt (line 77)) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from flake8==6.0.0->-r requirements.txt (line 77)) (2.10.0)\n",
            "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flake8==6.0.0->-r requirements.txt (line 77)) (3.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from brunette==0.2.8->-r requirements.txt (line 78)) (0.42.0)\n",
            "Requirement already satisfied: black==21.12b0 in /usr/local/lib/python3.10/dist-packages (from brunette==0.2.8->-r requirements.txt (line 78)) (21.12b0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from brunette==0.2.8->-r requirements.txt (line 78)) (8.1.7)\n",
            "Requirement already satisfied: tokenize-rt>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from add-trailing-comma==2.4.0->-r requirements.txt (line 80)) (5.2.0)\n",
            "Requirement already satisfied: pathspec<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black==21.12b0->brunette==0.2.8->-r requirements.txt (line 78)) (0.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black==21.12b0->brunette==0.2.8->-r requirements.txt (line 78)) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/aimclub/eXplain-NNs &> /dev/null\n",
        "\n",
        "!wget https://raw.githubusercontent.com/aimclub/eXplain-NNs/main/requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "# !pip install torchmetrics &> /dev/null\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset load and unzip for further use"
      ],
      "metadata": {
        "id": "M5bT7FCX5F2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to demonstrate the algorithm on the landscape classification from satellite imagery dataset [EuroSAT](https://www.kaggle.com/code/nilesh789/land-cover-classification-with-eurosat-dataset/notebook)"
      ],
      "metadata": {
        "id": "IGL5rSHgne3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "\n",
        "!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip\n",
        "!unzip EuroSAT.zip\n",
        "\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "LZO9vkjYj4hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage demonstration\n",
        "\n",
        "For demonstration of usage of module eXNN.bayes we train two simple networks - one will be more vulnerable to adversarial noise (undertrained), and one will be more robust. In order to distinguish them, we will use DropoutBayesianWrapper from eXNN.bayes in order to evaluate uncertainty of predictions for train and test input."
      ],
      "metadata": {
        "id": "DqYYm7y35L2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, load dataset and required libraries"
      ],
      "metadata": {
        "id": "e7ibWBEn565N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST, ImageFolder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as TF\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "path_to_data = '2750'\n",
        "\n",
        "dataset = ImageFolder(\n",
        "    path_to_data,\n",
        "    transform = TF.Compose([\n",
        "        TF.Resize((64, 64)),\n",
        "        TF.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "n_obj = 3000\n",
        "cls_indicies = [(i, obj) for i, obj in enumerate(dataset.targets)]\n",
        "shuffle(cls_indicies)\n",
        "\n",
        "cls_indicies = cls_indicies[0:n_obj]\n",
        "\n",
        "num_classes = len(dataset.classes)\n",
        "\n",
        "classes_names = dataset.classes\n",
        "\n",
        "train_ds = torch.utils.data.Subset(dataset, indices = [i[0] for i in cls_indicies[0:int(len(cls_indicies)*0.6)]])\n",
        "test_ds = torch.utils.data.Subset(dataset, indices = [i[0] for i in cls_indicies[int(len(cls_indicies)*0.6):]])\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=36, shuffle=True)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=36, shuffle=False)"
      ],
      "metadata": {
        "id": "6zgIaRijkJBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define training functions to train two models"
      ],
      "metadata": {
        "id": "kGX6EY7g6Fgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_model(model, device = 'cuda', good_case = True):\n",
        "  if good_case:\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay = 0.0001)#, momentum=0.9)\n",
        "  else:\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = 1e-1, weight_decay = 0, momentum = 0.9)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  images, labels = next(iter(train_dl))\n",
        "  #images = images.view(images.shape[0], -1)\n",
        "  logps = model(images)\n",
        "  loss = criterion(logps, labels)\n",
        "  # train\n",
        "  if good_case:\n",
        "    n_epochs = 20\n",
        "  else:\n",
        "    n_epochs = 5\n",
        "  for e in range(n_epochs):\n",
        "    time_mark = time.time()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_dl:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {} - Time taken: {} sec\".format(e, running_loss/len(train_dl), round(time.time() - time_mark, 2)))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "CYivAyNuscmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well train model"
      ],
      "metadata": {
        "id": "3kpcO4E96L6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_good = resnet18(num_classes=num_classes)\n",
        "\n",
        "model_good = train_model(model_good, device = 'cpu', good_case = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyijHKYfslFs",
        "outputId": "61e7f673-85ab-434a-cbcf-a4a1bca0bb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training loss: 1.9492802000045777 - Time taken: 36.93 sec\n",
            "Epoch 1 - Training loss: 1.5442372393608093 - Time taken: 34.69 sec\n",
            "Epoch 2 - Training loss: 1.3513949728012085 - Time taken: 40.52 sec\n",
            "Epoch 3 - Training loss: 1.2081313419342041 - Time taken: 35.22 sec\n",
            "Epoch 4 - Training loss: 1.0933070242404939 - Time taken: 35.03 sec\n",
            "Epoch 5 - Training loss: 0.9831119573116303 - Time taken: 35.17 sec\n",
            "Epoch 6 - Training loss: 0.8877223074436188 - Time taken: 35.31 sec\n",
            "Epoch 7 - Training loss: 0.8023216778039932 - Time taken: 34.3 sec\n",
            "Epoch 8 - Training loss: 0.7429862898588181 - Time taken: 36.59 sec\n",
            "Epoch 9 - Training loss: 0.6704698818922042 - Time taken: 35.02 sec\n",
            "Epoch 10 - Training loss: 0.6206120127439498 - Time taken: 38.32 sec\n",
            "Epoch 11 - Training loss: 0.5655347180366516 - Time taken: 41.13 sec\n",
            "Epoch 12 - Training loss: 0.4657299715280533 - Time taken: 37.05 sec\n",
            "Epoch 13 - Training loss: 0.41884350806474685 - Time taken: 36.12 sec\n",
            "Epoch 14 - Training loss: 0.3951619663834572 - Time taken: 35.22 sec\n",
            "Epoch 15 - Training loss: 0.3726543217897415 - Time taken: 34.79 sec\n",
            "Epoch 16 - Training loss: 0.3254171231389046 - Time taken: 36.1 sec\n",
            "Epoch 17 - Training loss: 0.28852191776037217 - Time taken: 35.09 sec\n",
            "Epoch 18 - Training loss: 0.2519600339233875 - Time taken: 35.01 sec\n",
            "Epoch 19 - Training loss: 0.21675407364964486 - Time taken: 34.62 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undertrain model"
      ],
      "metadata": {
        "id": "_IBzIy966PCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bad = resnet18(num_classes = num_classes)\n",
        "model_bad = train_model(model_bad, device = 'cpu', good_case = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtbGurK-smtm",
        "outputId": "511aa36b-f0fb-4c5f-b7be-d2896e53e3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training loss: 3.005459487438202 - Time taken: 32.29 sec\n",
            "Epoch 1 - Training loss: 1.8501051425933839 - Time taken: 31.88 sec\n",
            "Epoch 2 - Training loss: 1.5950738978385925 - Time taken: 32.72 sec\n",
            "Epoch 3 - Training loss: 1.4924990403652192 - Time taken: 32.19 sec\n",
            "Epoch 4 - Training loss: 1.4497403573989869 - Time taken: 33.98 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define one of the most popular adversarial noises - fgsm attack - in order to test the ability to distinguish between \"clean\" and \"noised\" examples (as seen by this model) - those for which model give reliable information and those for which it don't."
      ],
      "metadata": {
        "id": "0Il-vzGv6R0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define adversarial attack\n",
        "\n",
        "def fgsm_attack(model, loss, images, labels, eps, device):\n",
        "\n",
        "    images = images\n",
        "    labels = labels\n",
        "    images.requires_grad = True\n",
        "\n",
        "    outputs = model.forward(images)\n",
        "\n",
        "    model.zero_grad()\n",
        "    cost = loss(outputs, labels).to(device)\n",
        "    cost.backward()\n",
        "\n",
        "    attack_images = images + eps*images.grad.sign()\n",
        "    attack_images = torch.clamp(attack_images, 0, 1)\n",
        "\n",
        "    return attack_images\n",
        "\n",
        "def _d(t: torch.Tensor):\n",
        "    return t.detach().cpu()"
      ],
      "metadata": {
        "id": "8tG7xdn4wE5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_batches = 5\n",
        "\n",
        "train_iterator = iter(train_dl)\n",
        "batch = [(x[0], x[1]) for _, x in zip(range(n_batches), train_dl)]\n",
        "\n",
        "train_batch = [torch.cat([i for i,j in batch], dim = 0), torch.cat([j for i,j in batch], dim = 0)]\n",
        "\n",
        "corrupted_test = fgsm_attack(model = model_good, loss = torch.nn.NLLLoss(), images = train_batch[0], labels = train_batch[1], eps = 1e-2, device = 'cpu')"
      ],
      "metadata": {
        "id": "UE1azLYhwK9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import DropoutBayesianWrapper in order to give our model the ability to evaluate prediction uncertainty."
      ],
      "metadata": {
        "id": "yNGa2DX67qXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from eXNN.bayes import DropoutBayesianWrapper\n",
        "\n",
        "model_good_bayes = DropoutBayesianWrapper(model_good, 'beta', p = None, a = 0.6, b = 12.0)"
      ],
      "metadata": {
        "id": "zMSZaNE7whKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions for \"clean\" and \"noisy\" examples and compare prediction uncertainties for them"
      ],
      "metadata": {
        "id": "a6AQOhgN75q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svd_bayes_std_norm = model_good_bayes.predict(train_batch[0], n_iter = 10)['std'].detach().numpy()\n",
        "svd_bayes_std_corr = model_good_bayes.predict(corrupted_test, n_iter = 10)['std'].detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y0iWbE4mwkEd",
        "outputId": "6ccd062b-56b3-4ead-cb42-6f89670554ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "dropout(): argument 'input' (position 1) must be Tensor, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m svd_bayes_std_norm \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_good_bayes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m svd_bayes_std_corr \u001b[38;5;241m=\u001b[39m model_good_bayes\u001b[38;5;241m.\u001b[39mpredict(corrupted_test, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/eXNN/bayes/api.py:46\u001b[0m, in \u001b[0;36mDropoutBayesianWrapper.predict\u001b[0;34m(self, data, n_iter)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, n_iter) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124;03m\"\"\"Function computes mean and standard deviation of bayesian equivalent\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        of a neural network.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m        Dict[str, torch.Tensor]: dictionary with `mean` and `std` of prediction\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: res[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m: res[\u001b[38;5;241m1\u001b[39m]}\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/eXNN/bayes/wrapper.py:132\u001b[0m, in \u001b[0;36mNetworkBayesBeta.mean_forward\u001b[0;34m(self, data, n_iter)\u001b[0m\n\u001b[1;32m    130\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[0;32m--> 132\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    134\u001b[0m results \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(results, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    136\u001b[0m results \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    137\u001b[0m     [\n\u001b[1;32m    138\u001b[0m         torch\u001b[38;5;241m.\u001b[39mmean(results, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    142\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py:283\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py:266\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/eXNN/bayes/wrapper.py:49\u001b[0m, in \u001b[0;36mModuleBayesianWrapper.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 49\u001b[0m     weight, bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer, nn\u001b[38;5;241m.\u001b[39mLinear):\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(x, weight, bias)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/eXNN/bayes/wrapper.py:43\u001b[0m, in \u001b[0;36mModuleBayesianWrapper.dropout_weights\u001b[0;34m(self, weights, bias)\u001b[0m\n\u001b[1;32m     40\u001b[0m     p \u001b[38;5;241m=\u001b[39m Beta(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb))\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     42\u001b[0m weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(weights, p, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 43\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights, bias\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1279\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: dropout(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "res_uncert = pd.DataFrame()\n",
        "res_uncert['Group'] = [\"Normal\"]*len(svd_bayes_std_norm) + [\"Corrupted\"]*len(svd_bayes_std_corr)\n",
        "res_uncert[\"Uncert\"] = np.concatenate([svd_bayes_std_norm, svd_bayes_std_corr], axis = 0).mean(axis = 1)\n",
        "\n",
        "res_uncert"
      ],
      "metadata": {
        "id": "Fq8LjBYxwlkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot prediction uncertainties in order to see the difference between them"
      ],
      "metadata": {
        "id": "I7EXMGbM7_QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "res_uncert.boxplot(column = \"Uncert\", by = 'Group', figsize = (10, 5))\n",
        "plt.title(\"Uncertainty for corrupted and normal data\")"
      ],
      "metadata": {
        "id": "gap8roRjwnc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ind = 0\n",
        "\n",
        "ax[0].imshow(np.moveaxis(train_batch[0][ind].detach().numpy(), 0, -1))\n",
        "std1 = str(round(svd_bayes_std_norm[ind].mean(), 2))\n",
        "ax[0].set_title(f\"Prediction std: {std1}\")\n",
        "\n",
        "ax[1].imshow(np.moveaxis(corrupted_test[ind].detach().numpy(), 0, -1))\n",
        "std1 = str(round(svd_bayes_std_corr[ind].mean(), 2))\n",
        "ax[1].set_title(f\"Prediction std: {std1}\")"
      ],
      "metadata": {
        "id": "cuQ7Zux_8XgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qO8UocoL9nyG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}