{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as TF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDs(Dataset):\n",
    "    def __init__(self, pos_files, neg_files, tfm=None):\n",
    "        self.pos_files = pos_files\n",
    "        self.neg_files = neg_files\n",
    "        self.tfm = tfm\n",
    "    def __len__(self): return len(self.pos_files) + len(self.neg_files)\n",
    "    def __getitem__(self, i):\n",
    "        if i < len(self.pos_files):\n",
    "            pf = data_path / 'def_front' / self.pos_files[i]\n",
    "            lbl = 1\n",
    "        else:\n",
    "            pf = data_path / 'ok_front' / self.neg_files[i - len(self.pos_files)]\n",
    "            lbl = 0\n",
    "        image = Image.open(pf)\n",
    "        if self.tfm is not None:\n",
    "            image = self.tfm(image)\n",
    "        return image, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('casting_512x512')\n",
    "\n",
    "pos_files = sorted(os.listdir(data_path / 'def_front'))\n",
    "neg_files = sorted(os.listdir(data_path / 'ok_front'))\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(pos_files)\n",
    "np.random.shuffle(neg_files)\n",
    "\n",
    "_N = int(len(pos_files) * 0.8)\n",
    "trn_pos_files, val_pos_files = pos_files[:_N], pos_files[_N:]\n",
    "_N = int(len(neg_files) * 0.8)\n",
    "trn_neg_files, val_neg_files = neg_files[:_N], neg_files[_N:]\n",
    "_normalize = TF.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "tfm = TF.Compose([TF.Resize((256,256)), TF.ToTensor(), _normalize])\n",
    "\n",
    "trn_ds = MyDs(trn_pos_files, trn_neg_files, tfm=tfm)\n",
    "val_ds = MyDs(val_pos_files, val_neg_files, tfm=tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = torch.load('trained_model.pt').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial атака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, loss, images, labels, eps, device):\n",
    "    \n",
    "    images = images\n",
    "    labels = labels\n",
    "    images.requires_grad = True\n",
    "    \n",
    "    outputs = model.forward(images)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    cost = loss(outputs, labels).to(device)\n",
    "    cost.backward()\n",
    "    \n",
    "    attack_images = images + eps*images.grad.sign()\n",
    "    attack_images = torch.clamp(attack_images, 0, 1)\n",
    "    \n",
    "    return attack_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eXNN.NetBayesianization.api import BasicBayesianWrapper\n",
    "wrapper_model = BasicBayesianWrapper(model, \"beta\", p = None, a = 0.6, b = 12.0)\n",
    "\n",
    "simple_res = {\"acc\": [], \"uncert\": []}\n",
    "corrupted_res = {\"acc\": [], \"uncert\": []}\n",
    "\n",
    "example_normal = None\n",
    "example_error = None\n",
    "max_std = 0\n",
    "\n",
    "for i, img_data in enumerate(val_ds):\n",
    "    img, cls = img_data[0].cuda().unsqueeze(0), img_data[1]\n",
    "    pred = wrapper_model.predict(img, n_iter = 10)\n",
    "    simple_res[\"acc\"].append(pred[\"mean\"].cpu().detach().argmax().item() == cls)\n",
    "    simple_res[\"uncert\"].append(pred[\"std\"].cpu().detach().numpy())\n",
    "    \n",
    "    corrupted_img = fgsm_attack(model, nn.NLLLoss(), img, \n",
    "                        torch.LongTensor([cls]).cuda(), eps=0.01, device=device)\n",
    "    corrupted_pred = wrapper_model.predict(corrupted_img, n_iter = 10)\n",
    "    corrupted_res[\"acc\"].append(corrupted_pred[\"mean\"].cpu().detach().argmax().item() == cls)\n",
    "    corrupted_res[\"uncert\"].append(corrupted_pred[\"std\"].cpu().detach().numpy())\n",
    "    \n",
    "    if corrupted_pred[\"mean\"].cpu().detach().argmax().item() != pred[\"mean\"].cpu().detach().argmax().item():\n",
    "        if corrupted_pred[\"std\"].cpu().detach().mean().item() > max_std:\n",
    "            max_std = corrupted_pred[\"std\"].cpu().detach().mean().item()\n",
    "            example_error = [img.cpu().detach(), corrupted_img.cpu().detach(), \n",
    "                              {i: j.cpu().detach() for i, j in pred.items()},\n",
    "                              {i: j.cpu().detach() for i, j in corrupted_pred.items()}]\n",
    "    else:\n",
    "        example_normal = [img.cpu().detach(), corrupted_img.cpu().detach(), \n",
    "                          {i: j.cpu().detach() for i, j in pred.items()},\n",
    "                          {i: j.cpu().detach() for i, j in corrupted_pred.items()}]\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x25ec54913c8>,\n",
       "  <matplotlib.axis.XTick at 0x25edd501488>],\n",
       " <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "simple_data = np.array([np.mean(i) for i in simple_res[\"uncert\"]])\n",
    "corrupted_data = np.array([np.mean(i) for i in corrupted_res[\"uncert\"]])\n",
    "\n",
    "plt.boxplot([simple_data[simple_data < np.percentile(simple_data, 98)],\n",
    "             corrupted_data[corrupted_data < np.percentile(corrupted_data, 98)]])\n",
    "plt.xticks([1, 2], [\"clean\", \"noised\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_preproc(img):\n",
    "    img = (img - img.min())/(img.max() - img.min() + 1e-8)\n",
    "    img = img.cpu().detach().numpy()\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "    return img\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(viz_preproc(example_error[0].squeeze()))\n",
    "\n",
    "pred = example_error[2]\n",
    "mean, std = pred[\"mean\"].argmax().tolist(), [round(i, 2) for i in pred[\"std\"].squeeze().cpu().detach().tolist()]\n",
    "ax[0].set_title(\"Pred {} | Std {}\".format(mean, std))\n",
    "\n",
    "ax[1].imshow(viz_preproc(example_error[1].squeeze()))\n",
    "\n",
    "corrupted_pred = example_error[3]\n",
    "mean, std = corrupted_pred[\"mean\"].argmax().tolist(), [round(i, 2) for i in corrupted_pred[\"std\"].squeeze().cpu().detach().tolist()]\n",
    "ax[1].set_title(\"Pred {} | Std {}\".format(mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
